---
title: "catlvm : CATegorical Latent Variable Model"
subtitle: "Upward-Downward Algorithm"
author: 
 - name: "Youngsun Kim"
   email: "kim0sun@korea.ac.kr"
   address: "Department of Statistics \\newline Korea University"
fontsize: 11pt
fontfamily: mathpazo
kotex: true
# abstract: \lipsum[1]
# keywords: 
#  - "keyword 1"
#  - "keyword 2"
#  - "keyword 3"
#  - "..."
output: 
   ysktmplt::pdf_manuscript:
      keep_tex: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Hidden Markov tree {#hmt}


# Hierarchical latent class model {#hlca}
$$
\xi_{u}(k) = \textsf{Pr}\left[ \mathbf{Y}^{(u)} = \mathbf{y} | C_u = k \right] = 
\prod_{m = 1}^{M} \prod_{r = 1}^{R_m} \rho_{mr|k}^{I(y_m = r)},
\quad
\tau_{\rho(u), u}(l, k) = \textsf{Pr}\left[ C_u = k|C_{\rho(u)} = l \right],
\quad \text{and} \quad
\pi(k) = \textsf{Pr}(C_1 = k)
$$
Upward recursion
$$
\begin{aligned}
\beta_i^{(u)}(k) = 
\\
\beta_i^{(u,\rho(u))}(k) = 
\\
\beta_i^{(\rho(u))}(k) = 
\end{aligned}
$$

Downward recursion
$$
\begin{aligned}
\alpha_i^{(u)}(k) = \sum_{j}\frac{\tau_{j, k}^{(\rho(u), u)} \times \alpha_i^{(\rho(u))}(j) \times  \beta_i^{(\rho(u))}(j)}{\beta_{i}^{(u, \rho(u))}(j)}
\end{aligned}
$$

Posterior probabilties
$$
\begin{aligned}
\theta_{i}^{(u)}(k) &= \textsf{Pr}(C_u = k | \mathbf{y}_i) 
\\
&= \alpha_u(k) \times \beta_u(k)
\\
\theta_{i}^{\rho(u), u}(j,k) &= \textsf{Pr}(C_{\rho(u)} = j, C_u = k | \mathbf{y}_i) 
\\
&= \frac{\beta_i^{(u)}(k) \times \tau_{j, k}^{(\rho(u), u)} \times \alpha_i^{(\rho(u))}(j) \times  \beta_i^{(\rho(u))}(j)}{\beta_{i}^{(u, \rho(u))}(j)}
\end{aligned}
$$
